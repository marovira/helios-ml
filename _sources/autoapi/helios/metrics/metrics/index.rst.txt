helios.metrics.metrics
======================

.. py:module:: helios.metrics.metrics


Attributes
----------

.. autoapisummary::

   helios.metrics.metrics.METRICS_REGISTRY


Classes
-------

.. autoapisummary::

   helios.metrics.metrics.CalculatePSNR
   helios.metrics.metrics.CalculateSSIM
   helios.metrics.metrics.CalculateMAP
   helios.metrics.metrics.CalculateMAE


Functions
---------

.. autoapisummary::

   helios.metrics.metrics.create_metric


Module Contents
---------------

.. py:data:: METRICS_REGISTRY

   Global instance of the registry for metric functions.

   .. rubric:: Example

   .. code-block:: python

       import helios.metrics as hlm

       # This automatically registers your metric function.
       @hlm.METRICS_REGISTRY.register
       class MyMetric:
           ...

       # Alternatively you can manually register a metric function like this:
       hlm.METRICS_REGISTRY.register(MyMetric)

.. py:function:: create_metric(type_name: str, *args: Any, **kwargs: Any) -> torch.nn.Module

   Create the metric function for the given type.

   :param type_name: the type of the loss to create.
   :param args: positional arguments to pass into the metric.
   :param kwargs: keyword arguments to pass into the metric.

   :returns: The metric function


.. py:class:: CalculatePSNR(crop_border: int, input_order: str = 'HWC', test_y_channel: bool = False)

   Bases: :py:obj:`torch.nn.Module`


   Calculate PSNR (Peak Signal-to-Noise Ratio).

   Implementation follows: `<https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio>`__.
   Note that the input_order is only needed if you plan to evaluate Numpy images. It can
   be left as default otherwise.

   :param crop_border: Cropped pixels in each edge of an image. These pixels are not
                       involved in the calculation.
   :param input_order: Whether the input order is "HWC" or "CHW". Defaults to "HWC".
   :param test_y_channel: Test on Y channel of YCbCr. Defaults to false.


   .. py:method:: forward(img: numpy.typing.NDArray | torch.Tensor, img2: numpy.typing.NDArray | torch.Tensor) -> float

      Calculate the PSNR metric.

      :param img: Images with range :math:`[0, 255]`.
      :param img2: Images with range :math:`[0, 255]`.

      :returns: PSNR value.



.. py:class:: CalculateSSIM(crop_border: int, input_order: str = 'HWC', test_y_channel: bool = False)

   Bases: :py:obj:`torch.nn.Module`


   Calculate SSIM (structural similarity).

   Implementation follows: 'Image quality assesment: From error visibility to structural
   similarity'. Results are identical to those of the official MATLAB code in
   `<https://ece.uwaterloo.ca/~z70wang/research/ssim/>`__.
   For three-channel images, SSIM is calculated for each channel and then
   averaged.

   :param crop_border: Cropped pixels in each edge of an image. These pixels are not
                       involved in the calculation.
   :param input_order: Whether the input order is "HWC" or "CHW". Defaults to "HWC".
   :param test_y_channel: Test on Y channel of YCbCr. Defaults to false.


   .. py:method:: forward(img: numpy.typing.NDArray | torch.Tensor, img2: numpy.typing.NDArray | torch.Tensor) -> float

      Calculate the SSIM metric.

      :param img: Images with range :math:`[0, 255]`.
      :param img2: Images with range :math:`[0, 255]`.

      :returns: PSNR value.



.. py:class:: CalculateMAP(*args, **kwargs)

   Bases: :py:obj:`torch.nn.Module`


   Calculate the mAP (Mean Average Precision).

   Implementation follows:
   `<https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision>`__.


   .. py:method:: forward(targs: numpy.typing.NDArray, preds: numpy.typing.NDArray) -> float

      Calculate the mAP (Mean Average Precision).

      :param targs: target (inferred) labels in range :math:`[0, 1]`.
      :param preds: predicate labels in range :math:`[0, 1]`.

      :returns: The mAP score



.. py:class:: CalculateMAE(scale: float = 1)

   Bases: :py:obj:`torch.nn.Module`


   Compute the MAE (Mean-Average Precision) score.

   Implementation follows: `<https://en.wikipedia.org/wiki/Mean_absolute_error>`__.
   The scale argument is used in the event that the input arrays are not in the range
   :math:`[0, 1]` but instead have been scaled to be in the range :math:`[0, N]` where
   :math:`N` is the factor. For example, if the arrays are images in the range
   :math:`[0, 255]`, then the scaling factor should be set to 255. If the arrays are
   already in the range :math:`[0, 1]`, then the scale can be omitted.

   :param scale: scaling factor that was used on the input tensors. Defaults to 1.


   .. py:method:: forward(pred: numpy.typing.NDArray | torch.Tensor, gt: numpy.typing.NDArray | torch.Tensor) -> float

      Calculate the MAE metric.

      :param pred: predicate (inferred) data.
      :param gt: ground-truth data.

      :returns: The MAE score



